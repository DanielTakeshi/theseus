{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Differentiating Through Theseus Layers</h1>\n",
    "\n",
    "This tutorial shows how we can differentiate through Theseus layers to solve a collection of related least-squares optimization problems. \n",
    "\n",
    "The optimization problems of Tutorial 1 are done with one application (each) of the Theseus non-linear least squares optimizers, as they are straightforward curve-fitting problems. Theseus can also be used to solve more complex optimization problems, e.g., with dependencies between the quantities being optimized. In this tutorial, we will solve a set of curve-fitting problems that share one common parameter. As in Tutorial 1, we choose quadratic functions for simplicity: we wish to fit <i>y = ax<sup>2</sup> + b</i>, where <i>a</i> is fixed for all problems, and <i>b</i> is different for each problem. \n",
    "\n",
    "At a high-level, we solve this problem by using torch automatic differentiation to optimize the value of <i>a</i>, and optimize <i>b</i> for a given <i>a</i> with the non-linear least squares optimizers in Theseus. The rest of this notebook works through the necessary steps in detail. \n",
    "\n",
    "Daniel: why *specifically* do we do it this way with $a$ and $b$? Are there other ways?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 0: Data Generation</h2> \n",
    "\n",
    "As before, we first generate data by sampling points from a set of quadratic functions <i>3x<sup>2</sup> + b</i>, where <i>b = 3, 5, ..., 21</i>. To this, we add Gaussian noise with <i>&sigma; = 0.01</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def generate_data(num_points=100, a=1, b=0.5, noise_factor=0.01):\n",
    "    # Generate data: 100 points sampled from the quadratic curve listed above\n",
    "    data_x = torch.rand((1, num_points))\n",
    "    noise = torch.randn((1, num_points)) * noise_factor\n",
    "    data_y = a * data_x.square() + b + noise\n",
    "    return data_x, data_y\n",
    "\n",
    "def generate_learning_data(num_points, num_models):\n",
    "    a, b = 3, 1\n",
    "    data_batches = []\n",
    "    for i in range(num_models):\n",
    "        b = b + 2\n",
    "        data = generate_data(num_points, a, b)\n",
    "        data_batches.append(data)\n",
    "    return data_batches\n",
    "\n",
    "num_models = 10\n",
    "data_batches = generate_learning_data(100, num_models)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(num_models):\n",
    "    ax.scatter(data_batches[i][0], data_batches[i][1])\n",
    "ax.set_xlabel('x');\n",
    "ax.set_ylabel('y');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 1: Set up Theseus Optimization</h2>\n",
    "\n",
    "Next, we set up the Theseus optimization problem similar to Tutorial 1, but with one key change: <i>a</i> is no longer an optimization variable for the Theseus NLLS optimizer; instead, it is an auxiliary variable whose value will be optimized by PyTorch through backpropagation. <i>b</i> remains the only optimization variable for the Theseus NLLS optimizer. The code below illustrates this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theseus as th\n",
    "\n",
    "data_x, data_y = data_batches[0]\n",
    "x = th.Variable(data_x, name=\"x\")\n",
    "y = th.Variable(data_y, name=\"y\")\n",
    "a = th.Vector(1, name=\"a\")\n",
    "b = th.Vector(1, name=\"b\")\n",
    "\n",
    "# Note 'b' is the only optim_var, and 'a' is part of aux_vars\n",
    "optim_vars = [b]\n",
    "aux_vars = a, x, y\n",
    "\n",
    "# updated error function reflects change in 'a'\n",
    "# Daniel: same as in prior tutorial otherwise. Note: b should just be (1,1) shaped,\n",
    "# or 1, it's not of length 10 here.\n",
    "def quad_error_fn2(optim_vars, aux_vars):\n",
    "    [b] = optim_vars \n",
    "    a, x, y = aux_vars\n",
    "    est = a.tensor * x.tensor.square() + b.tensor\n",
    "    err = y.tensor - est\n",
    "    return err\n",
    "\n",
    "cost_function = th.AutoDiffCostFunction(\n",
    "    optim_vars, quad_error_fn2, 100, aux_vars=aux_vars, name=\"quadratic_cost_fn\"\n",
    ")\n",
    "objective = th.Objective()\n",
    "objective.add(cost_function)\n",
    "optimizer = th.GaussNewton(\n",
    "    objective,\n",
    "    max_iterations=50,\n",
    "    step_size=0.5,\n",
    ")\n",
    "theseus_optim = th.TheseusLayer(optimizer)\n",
    "\n",
    "# The value for Variable 'a' is optimized by PyTorch backpropagation\n",
    "a_tensor = torch.nn.Parameter(torch.rand(1, 1))\n",
    "model_optimizer = torch.optim.Adam([a_tensor], lr=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 2: Run Optimization and Learning</h2> \n",
    "\n",
    "Finally, we compute <i>a</i> and <i>b</i> by using a learning loop around the Theseus NLLS optimizer, with each model's data taken as a single batch. The Theseus NLLS optimizer optimizes `b` for the current `a` (referred to as the <i>inner loop optimization</i>), while the PyTorch backpropagation learns the correct value to use for `a` across the batches (referred to as the <i>outer loop optimization</i>). \n",
    "\n",
    "For clarity, we describe the high-level steps required:\n",
    "- Step 2.1: As in Tutorial 1, we begin by creating a dictionary of inputs, and pass it to the `forward` function of the `TheseusLayer`. Note that the `forward` function here does not track the best solution in this example, as the entire NLLS optimization sequence needs to be used for backpropagation. \n",
    "After the optimization completes in the `TheseusLayer`, we get a dictionary `updated_inputs` with latest values of the optimization variables (and all other dictionary values unchanged). \n",
    "- Step 2.2: We then update the `objective` with the `updated_inputs` dictionary, and use it to compute the loss. This kind of use of the Theseus optimization variables is the reason the `forward` returns a dictionary of inputs.\n",
    "- Step 2.3: This loss is used for backpropagation. The PyTorch learning optimizer (i.e. Adam here) will now take one optimization step for the learning parameters (i.e., `a`'s value in this example).\n",
    "- Iterate: We now make a new call to `forward`, repeating Steps 2.1-2.3. \n",
    "\n",
    "We illustrate these steps in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = len(data_batches)\n",
    "num_epochs = 20\n",
    "\n",
    "print(f\"Initial a value: {a_tensor.item()}\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.\n",
    "    epoch_b = []  # keep track of the current b values for each model in this epoch\n",
    "\n",
    "    # Daniel: this is what they suggest to do in comments. If doing this, comment out\n",
    "    # the 'a' part in the `theseus_inputs` dict.\n",
    "    #a.update(a_tensor)\n",
    "\n",
    "    # Daniel: iterates over each of the datasets (i.e., each of the `b` values).\n",
    "    for i in range(num_batches):\n",
    "        model_optimizer.zero_grad()\n",
    "        data_x, data_y = data_batches[i]\n",
    "\n",
    "        # Step 2.1: Create input dictionary for TheseusLayer, pass to forward function\n",
    "        # The value for variable `a` is the updated `a_tensor` by Adam\n",
    "        # Since we are always passing the same tensor, this update is technically redundant, \n",
    "        # we include it to explicitly illustrate where variable values come from.\n",
    "        # An alternative way to do this (try it!)\n",
    "        # would be to call `a.update(a_tensor)` before the learning loop starts\n",
    "        # and just let Adam change its value under the hood (i.e., update only `x`, `y`, and `b`\n",
    "        # inside the loop)\n",
    "        # Daniel: we do need a_tensor here, we can't comment it out. (If we run it for the\n",
    "        # first time.) To do what they suggest see the code I put above.\n",
    "        theseus_inputs = {\n",
    "            \"a\": a_tensor,              # aux var, technically redundant as shown above\n",
    "            \"x\": data_x,                # aux var, as usual\n",
    "            \"y\": data_y,                # aux var, as usual\n",
    "            \"b\": torch.ones((1, 1)),    # optim var, init value\n",
    "        }\n",
    "        updated_inputs, info = theseus_optim.forward(theseus_inputs)\n",
    "        # add the optimized \"b\" of the current batch to `epoch_b` list. \n",
    "        # Note: here, we do not track the best solution, as we \n",
    "        # backpropagate through the entire optimization sequence.\n",
    "        # Daniel: each updated_inputs['b'] is a (1,1)-shaped tensor, as expected.\n",
    "        epoch_b.append(updated_inputs[\"b\"].item())\n",
    "\n",
    "        # Step 2.2: Update objective function with updated inputs\n",
    "        objective.update(updated_inputs)\n",
    "        loss = cost_function.error().square().mean()\n",
    "\n",
    "        # Step 2.3: PyTorch backpropagation\n",
    "        # Daniel: model_optimizer only includes a_tensor, so we don't change b here.\n",
    "        loss.backward()\n",
    "        model_optimizer.step()\n",
    "        loss_value = loss.item()\n",
    "        epoch_loss += loss_value\n",
    "\n",
    "    print(f\"Epoch: {epoch} Loss: {epoch_loss}\")\n",
    "    if epoch % 5 == 4:\n",
    "        print(f\" ---------------- Solutions at Epoch {epoch:02d} -------------- \")\n",
    "        print(\" a value:\", a.tensor.item())\n",
    "        print(\" b values: \", epoch_b)\n",
    "        print(f\" ----------------------------------------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learned functions\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(num_models):\n",
    "    ax.scatter(data_batches[i][0], data_batches[i][1])\n",
    "\n",
    "    a_ = a.tensor.squeeze().detach()\n",
    "    b = epoch_b[i]\n",
    "    x = torch.linspace(0., 1., steps=100)\n",
    "    y = a_*x*x + b\n",
    "    ax.plot(x, y, color='k', lw=4, linestyle='--',\n",
    "            label='Learned quadratics' if i == 0 else None)\n",
    "ax.legend()\n",
    "\n",
    "ax.set_xlabel('x');\n",
    "ax.set_ylabel('y');\n",
    "# Daniel: LGTM, we can fit well to all 10 of the data curves ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that we are able to recover `a` and `b` very close to the values we sampled from. \n",
    "\n",
    "<h2>Step 3 (Optional): Solving all Optimization Problems Simultaneously</h2>\n",
    "\n",
    "The above is only one of many ways to model our problem with Theseus. Theseus also supports solving multiple optimization problems simultaneously, so we could also solve all of the 10 least-squares optimization problems simultaneously. We can do this in two natural ways:\n",
    "- Version A: by creating 10 `AutoDiffCostFunction`s, one for each optimization problem. Here, we need each `AutoDiffCostFunction` to have a separate `b, x, y` variables (e.g., `[b1, x1, y1]`, `[b2, x2, y2]` etc). All cost functions are added to the objective, and they can be optimized jointly with one `forward`, and differentiated through jointly with the following `backward`. \n",
    "- Version B: by changing the `b, x, y` variables to be batched, and having the error function above `quad_err_fn2` to support batches, we can use a single `AutoDiffCostFunction` to capture the cost of their fit. However, because the error may now be batched, the loss has to be computed as an aggregate of the evaluated objective. \n",
    "\n",
    "Version A is more commonly used in situations where each variable and cost-function has a different sematic interpretation (e.g., different time-steps in the motion-planning problem of Tutorial 4 & 5), while Version B is commonly used for multiple instances of the same problem (e.g., different maps in Tutorials 4 & 5). We show below the complete code for each version. Both versions find very similar `a` and `b` values. \n",
    "\n",
    "Because both versions need a common learning routine, we first create a subroutine `optimize_and_learn_models_jointly` for readability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-routine to optimize and learn models simultaneously\n",
    "# Daniel: again, this is used for both versions.\n",
    "\n",
    "def optimize_and_learn_models_jointly(theseus_optim, model_optimizer, num_epochs=20):\n",
    "    # again, assume a_tensor is initialized outside this loop\n",
    "    print(f\"Initial a value: {a_tensor.item()}\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model_optimizer.zero_grad()\n",
    "        # Step 2.1: Create input dictionary for TheseusLayer, pass to forward function\n",
    "        # Daniel: don't worry, we'll define this function later.\n",
    "        theseus_inputs = construct_theseus_layer_inputs()\n",
    "        updated_inputs, _ = theseus_optim.forward(theseus_inputs)\n",
    "\n",
    "        # Step 2.2: Update objective function with updated inputs\n",
    "        objective.update(updated_inputs)\n",
    "        loss = objective.error_squared_norm()   # Daniel: again use error_squared_norm\n",
    "        loss = loss.sum()  # Note `loss` now needs a final aggregation (for version B)\n",
    "\n",
    "        # Step 2.3: PyTorch backpropagation\n",
    "        loss.backward()\n",
    "        model_optimizer.step()\n",
    "\n",
    "        if epoch == 0:\n",
    "            min_loss = loss\n",
    "        if loss <= min_loss:\n",
    "            min_loss = loss\n",
    "            best_model_a = a.tensor.item()\n",
    "            best_model_b = [b.tensor.item() for b in all_b]\n",
    "\n",
    "        print(f\"Epoch: {epoch} Loss: {loss.item()}\")\n",
    "        if epoch % 10 == 9:\n",
    "            print(f\" ---------------- Solutions at Epoch {epoch:02d} -------------- \")\n",
    "            print(\" a value:\", a.tensor.item())\n",
    "            print(\" b values: \", [b.tensor.item() for b in all_b])\n",
    "            print(f\" ----------------------------------------------------- \")\n",
    "\n",
    "    return best_model_a, best_model_b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 3.1: Example Version A</h3>\n",
    "\n",
    "Now we show Version A. This version makes the following changes from the original code snippet:\n",
    "- create 10 `x`, `y` and `b` variables.\n",
    "- create 10 `AutoDiffCostFunctions`, each using the same `a` but the corresponding `b_i`, `x_i` and `y_i`. All cost functions are added to the objective.\n",
    "- construct the `theseus_inputs` dictionary with the `b_i`, `x_i` and `y_i` mapped to the correct data batch.\n",
    "\n",
    "Note that `a` and its setup the PyTorch optimizer remain the same. Once the optimization problem is setup, we call `optimize_and_learn_models_jointly` sub-routine to compute the `a` and `b` values.\n",
    "\n",
    "Daniel: hmm ... I just ran these and it seems a bit off / worse than what's earlier? Of course it's still very close and got to a reasonable solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version A\n",
    "\n",
    "# replace x and y with 10 different variables x0 ... x9, y0 ... y9\n",
    "all_x, all_y = [], []\n",
    "for i in range(num_models): \n",
    "    all_x.append(th.Variable(data_x, name=f\"x{i}\"))\n",
    "    all_y.append(th.Variable(data_y, name=f\"y{i}\"))\n",
    "\n",
    "# replace b with 10 different variables b0 ... b9\n",
    "all_b = []\n",
    "for i in range(num_models):\n",
    "    all_b.append(th.Vector(1, name=f\"b{i}\"))\n",
    "\n",
    "# a remains the same\n",
    "a = th.Vector(1, name=\"a\")\n",
    "\n",
    "# objective now has 10 different cost functions\n",
    "objective = th.Objective()\n",
    "for i in range(num_models):\n",
    "    # each cost function i uses b_i as optim_var and x_i, y_i and a as aux_var\n",
    "    optim_vars = [all_b[i]]\n",
    "    aux_vars = a, all_x[i], all_y[i]\n",
    "    cost_function = th.AutoDiffCostFunction(\n",
    "        optim_vars, quad_error_fn2, 100, aux_vars=aux_vars, name=f\"quadratic_cost_fn_{i}\"\n",
    "    )\n",
    "    objective.add(cost_function)\n",
    "\n",
    "# optimizer, TheseusLayer and model optimizer remains the same\n",
    "optimizer = th.GaussNewton(\n",
    "    objective, max_iterations=50, step_size=0.4,\n",
    ")\n",
    "theseus_optim = th.TheseusLayer(optimizer)\n",
    "a_tensor = torch.nn.Parameter(torch.rand(1, 1))\n",
    "model_optimizer = torch.optim.Adam([a_tensor], lr=0.15)\n",
    "\n",
    "# TheseusLayer dictionary now needs to construct b0 ... b9, x0 ... x9, y0 ... y9\n",
    "def construct_theseus_layer_inputs():\n",
    "    theseus_inputs = {}\n",
    "    for i in range(num_models):\n",
    "        data_x, data_y = data_batches[i]\n",
    "        theseus_inputs.update({\n",
    "            f\"x{i}\": data_x,\n",
    "            f\"y{i}\": data_y,\n",
    "            f\"b{i}\": torch.ones((1, 1)),\n",
    "        })\n",
    "    theseus_inputs.update({\"a\": a_tensor})\n",
    "    return theseus_inputs\n",
    "\n",
    "# Run Theseus optimization and learning\n",
    "best_model = optimize_and_learn_models_jointly(theseus_optim, model_optimizer)\n",
    "\n",
    "print(f\" ---------------- Final Solutions -------------- \")\n",
    "print(\" a value:\", best_model[0])\n",
    "print(\" b values: \", best_model[1])\n",
    "print(f\" ----------------------------------------------- \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learned functions\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(num_models):\n",
    "    ax.scatter(data_batches[i][0], data_batches[i][1])\n",
    "\n",
    "    a = best_model[0]\n",
    "    b = best_model[1][i]\n",
    "    x = torch.linspace(0., 1., steps=100)\n",
    "    y = a*x*x + b\n",
    "    ax.plot(x, y, color='k', lw=4, linestyle='--',\n",
    "            label='Learned quadratics' if i == 0 else None)\n",
    "ax.legend()\n",
    "\n",
    "ax.set_xlabel('x');\n",
    "ax.set_ylabel('y');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Step 3.2: Example Version B</h3>\n",
    "\n",
    "Now we show Version B. This version makes the following changes from the original code snippet:\n",
    "- create `x`, `y` variables of sizes `[num_models, 100]` instead of `[1, 100]`\n",
    "- create `b` variable of size `[num_models, 1]` instead of `[1, 1]`\n",
    "- construct the `theseus_inputs` dictionary with `b`, `x` and `y` data batched\n",
    "\n",
    "In this example, we do not need to change the error function, because PyTorch tensors handle the broadcasting for the batched version to work. \n",
    "\n",
    "As before, `a` and its setup for the PyTorch optimizer remain the same. Once the optimization problem is setup, we call `optimize_and_learn_models_jointly` sub-routine to solve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version B\n",
    "\n",
    "# convert data_x, data_y into torch.tensors of shape [num_models, 100]\n",
    "data_x = torch.stack([data_x.squeeze() for data_x, _ in data_batches])\n",
    "data_y = torch.stack([data_y.squeeze() for _, data_y in data_batches])\n",
    "\n",
    "# construct one variable each of x, y of shape [num_models, 100]\n",
    "x = th.Variable(data_x, name=\"x\")\n",
    "y = th.Variable(data_y, name=\"y\")\n",
    "\n",
    "# construct a as before\n",
    "a = th.Vector(1, name=\"a\")\n",
    "\n",
    "# construct one variable b, now of shape [num_models, 1]\n",
    "b = th.Vector(tensor=torch.rand(num_models, 1), name=\"b\")\n",
    "\n",
    "# Again, 'b' is the only optim_var, and 'a' is part of aux_vars along with x, y\n",
    "optim_vars = [b]\n",
    "aux_vars = a, x, y\n",
    "\n",
    "# cost function constructed as before \n",
    "cost_function = th.AutoDiffCostFunction(\n",
    "    optim_vars, quad_error_fn2, 100, aux_vars=aux_vars, name=\"quadratic_cost_fn\"\n",
    ")\n",
    "\n",
    "# objective, optimizer and theseus layer constructed as before\n",
    "objective = th.Objective()\n",
    "objective.add(cost_function)\n",
    "optimizer = th.GaussNewton(\n",
    "    objective, max_iterations=50, step_size=0.5,\n",
    ")\n",
    "theseus_optim = th.TheseusLayer(optimizer)\n",
    "\n",
    "# As before, 'a' is optimized by PyTorch backpropagation\n",
    "# model_optimizer constructed the same way \n",
    "a_tensor = torch.nn.Parameter(torch.rand(1, 1))\n",
    "model_optimizer = torch.optim.Adam([a_tensor], lr=0.2)\n",
    "\n",
    "# The theseus_inputs dictionary is also constructed similarly to before,\n",
    "# but with data matching the new shapes of the variables\n",
    "def construct_theseus_layer_inputs():\n",
    "    theseus_inputs = {}\n",
    "    theseus_inputs.update({\n",
    "        \"x\": data_x,\n",
    "        \"y\": data_y,\n",
    "        \"b\": torch.ones((num_models, 1)),\n",
    "        \"a\": a_tensor,\n",
    "    })\n",
    "    return theseus_inputs\n",
    "\n",
    "# Run Theseus optimization and learning\n",
    "best_model = optimize_and_learn_models_jointly(theseus_optim, model_optimizer)\n",
    "print(f\" ---------------- Final Solutions -------------- \")\n",
    "print(\" a value:\", best_model[0])\n",
    "print(\" b values: \", best_model[1])\n",
    "print(f\" ----------------------------------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learned functions\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(num_models):\n",
    "    ax.scatter(data_batches[i][0], data_batches[i][1])\n",
    "\n",
    "    a = best_model[0]\n",
    "    b = best_model[1][i]\n",
    "    x = torch.linspace(0., 1., steps=100)\n",
    "    y = a*x*x + b\n",
    "    ax.plot(x, y, color='k', lw=4, linestyle='--',\n",
    "            label='Learned quadratics' if i == 0 else None)\n",
    "ax.legend()\n",
    "\n",
    "ax.set_xlabel('x');\n",
    "ax.set_ylabel('y');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technical note: You may note that in this example, the differentiation occurs only through the TheseusLayer objective, not through the Theseus non-linear least squares optimizers. This is due to the simplicity of the example problem. A more complex series of inner loop computations will require Theseus to also differentiate through the non-linear least squares optimizers; such problems are in Tutorials 4 & 5, as well as in the [Theseus `examples` folder](https://github.com/facebookresearch/theseus/tree/main/examples)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "theseus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
